{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyN+qlVlOtsAAcHqYmWVR96Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitrijLeontev/Dmitrij_Leontev/blob/main/%D1%81%D1%82%D0%B0%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B8%20/%D0%90%D0%B9%D0%A2%D0%B8%D0%9E%D0%BD_%D0%B7%D0%B0%D0%BC%D0%B5%D0%BD%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2%D1%8B%D1%85_%D1%84%D0%B8%D0%BB%D1%8C%D1%82%D1%80%D0%BE%D0%B2/%D0%9F%D1%80%D0%BE%D0%B1%D1%83%D0%B5%D0%BC_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем нейросеть\n",
        "\n",
        "Обработка аудиосигналов: Параметризация аудио Импорт библиотек\n",
        "\n",
        "В первую очередь импортируйте библиотеки и необходимые инструменты:\n",
        "\n",
        "librosa – инструменты для работы с аудиосигналом; librosa.display – инструмент для визуализации аудио; IPython.display as ipd – проигрывание аудио в ноутбуке.\n",
        "\n",
        "Сгенерируйте данные для обучения модели МОДЕЛЬ ПРЕОБРАЗОВАНИЯ TEXT-TO-SPEECH SILERO используется как предварительно обученная модель из PyTorch."
      ],
      "metadata": {
        "id": "JHdxO2cWvIgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkzGXKCTu4Cc"
      },
      "outputs": [],
      "source": [
        "# Подключаем гугл диск\n",
        "\n",
        "# data_path = '/content/drive/MyDrive/Colab Notebooks/stagirovki/stagirov_robot/datasetitexzad/raspacovannie/golosblizko/dvigaisvper.WAV'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка аудиосигналов: Параметризация аудио Импорт библиотек\n",
        "\n",
        "В первую очередь импортируйте библиотеки и необходимые инструменты:\n",
        "\n",
        "librosa – инструменты для работы с аудиосигналом; librosa.display – инструмент для визуализации аудио; IPython.display as ipd – проигрывание аудио в ноутбуке."
      ],
      "metadata": {
        "id": "n6GVldoMvdqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите необходимый датасет по ссылке при помощи gdown.download() и разархивируйте его:"
      ],
      "metadata": {
        "id": "iYK2sSGTvi39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q audiomentations"
      ],
      "metadata": {
        "id": "oA37KgKeve4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cylimiter"
      ],
      "metadata": {
        "id": "cAo9UgigvpsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import librosa as lb\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "from random import choice\n",
        "import pickle"
      ],
      "metadata": {
        "id": "IssOEedUvyL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import functions and create object for transformation\n",
        "from audiomentations import Compose, AddGaussianNoise, AirAbsorption, Limiter, RepeatPart, TanhDistortion, TimeMask"
      ],
      "metadata": {
        "id": "ClQvnG8Cv1Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from audiomentations import TimeStretch"
      ],
      "metadata": {
        "id": "uCuHUpa7v6NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1kIZOkBIKIrLWqcgptDolg58rb5N1Q-vY/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=1kIZOkBIKIrLWqcgptDolg58rb5N1Q-vY', None, quiet=True)\n",
        "!unzip -qo forward.zip"
      ],
      "metadata": {
        "id": "MX9NmcEswR_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/10OIASzdWFzdOPrLJTSA5Ghd9ihfMHoQX/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=10OIASzdWFzdOPrLJTSA5Ghd9ihfMHoQX', None, quiet=True)\n",
        "!unzip -qo backward.zip"
      ],
      "metadata": {
        "id": "hVEYKXRawTyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1KRusO1t6zrl2rprUjf2NBKwjxrj3V07j/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=1KRusO1t6zrl2rprUjf2NBKwjxrj3V07j', None, quiet=True)\n",
        "!unzip -qo left.zip"
      ],
      "metadata": {
        "id": "OM3jkBqUwYi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/15Tim1Au-g5DP74RVQNGfpvqmziAueayI/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=15Tim1Au-g5DP74RVQNGfpvqmziAueayI', None, quiet=True)\n",
        "!unzip -qo right.zip"
      ],
      "metadata": {
        "id": "do5Spdqfwefr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1owkxkb0gMvucD83Lx6VAmOKp_uvcw8gu/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=1owkxkb0gMvucD83Lx6VAmOKp_uvcw8gu', None, quiet=True)\n",
        "!unzip -qo stop.zip"
      ],
      "metadata": {
        "id": "yN34niwnwlWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "9f-8UBxpwvjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(folder, size=100):\n",
        "    \"\"\"\n",
        "    функция принимает путь к каталогу и случайным образом берет из него аудио файл\n",
        "    для генерации данных\n",
        "    folder: путь к каталогу\n",
        "    size: размер генерированного списка\n",
        "    return: возвращает список генерированных команд размером size\n",
        "    \"\"\"\n",
        "    augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.04, p=0.5),\n",
        "    AirAbsorption(min_distance=300.0, max_distance=700.0, p=0.5),\n",
        "    Limiter(min_threshold_db=-40.0, max_threshold_db=-0.0, threshold_mode=\"relative_to_signal_peak\", p=0.5),\n",
        "    TanhDistortion(min_distortion=0.01, max_distortion=0.7, p=0.5),\n",
        "    TimeMask(min_band_part=0.1, max_band_part=0.2, fade=True, p=0.5),\n",
        "    TimeStretch(min_rate=0.7, max_rate=1.5, leave_length_unchanged=True, p=0.5),\n",
        "])\n",
        "    data_x, data_y = list(), list()\n",
        "    for _ in range(size):\n",
        "        x, sr = lb.load(os.path.join(folder, choice(os.listdir(folder))))\n",
        "        data = augment(x, sr)\n",
        "        data_x.append(list(data))\n",
        "        data_y.append(folders.index(folder))\n",
        "\n",
        "    print(f'the length of the list x: {len(data_x)}, y: {len(data_y)}')\n",
        "    return data_x, data_y"
      ],
      "metadata": {
        "id": "i-AaCa8nww-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = list(), list()\n",
        "folders = ['./forward', './backward', './left', './right', './stop']\n",
        "\n",
        "\n",
        "for folder in folders:\n",
        "    data_x, data_y = transformer(folder, 200)\n",
        "    train_x.extend(data_x)\n",
        "    train_y.extend(data_y)"
      ],
      "metadata": {
        "id": "iMr624IGw6mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_y), len(train_x), train_y[480]"
      ],
      "metadata": {
        "id": "DRVKulgXxAEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('./data.pickle', 'wb') as f:\n",
        "#     pickle.dump((train_x, train_y), f)\n",
        "\n",
        "# with open('./data.pickle', 'rb') as f:\n",
        "#     data_x, data_y = pickle.load(f)"
      ],
      "metadata": {
        "id": "ZIVBwK1dxGUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1q3pyc19MFE0Bhha_BYTUKnKicYigIxV-/view?usp=sharing\n",
        "gdown.download('https://drive.google.com/uc?id=1q3pyc19MFE0Bhha_BYTUKnKicYigIxV-', None, quiet=True)"
      ],
      "metadata": {
        "id": "T-Mb_3xuxO1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./data.pickle', 'rb') as f:\n",
        "    data_x, data_y = pickle.load(f)"
      ],
      "metadata": {
        "id": "B9XMa4oPxUkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_x), len(data_y)"
      ],
      "metadata": {
        "id": "Pqo03MnwxZlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(data=data_x[676], rate=22050)"
      ],
      "metadata": {
        "id": "aAMZ6dGvxem7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 828\n",
        "print(data_y[idx], len(data_x[idx]))"
      ],
      "metadata": {
        "id": "wTIorhboxi_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# постоянные переменные\n",
        "SR = 22050 # частота дискретизации\n",
        "HP = 200 # размер окна\n",
        "FT = 500 # размер окна преобразования Фурье\n",
        "CC = len(folders) # количество классов"
      ],
      "metadata": {
        "id": "KSX9ovBXxoQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция параметризации аудио\n",
        "\n",
        "def get_features(y,                     # волновое представление сигнала\n",
        "                 sr=SR,                   # частота дискретизации сигнала y\n",
        "                 n_fft=FT,           # размер скользящего окна БПФ\n",
        "                 hop_length=HP  # шаг скользящего окна БПФ\n",
        "                 ):\n",
        "    # Вычисление различных параметров (признаков) аудио\n",
        "\n",
        "    # Среднеквадратическая амплитуда\n",
        "    rmse = lb.feature.rms(y=y, hop_length=hop_length)\n",
        "    # Спектральный центроид\n",
        "    spec_cent = lb.feature.spectral_centroid(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "    # Ширина полосы частот\n",
        "    spec_bw = lb.feature.spectral_bandwidth(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "    # Спектральный спад частоты\n",
        "    rolloff = lb.feature.spectral_rolloff(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "    # Пересечения нуля\n",
        "    zcr = lb.feature.zero_crossing_rate(y, hop_length=hop_length)\n",
        "    # Мел-кепстральные коэффициенты\n",
        "    mfcc = lb.feature.mfcc(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "    # Хромаграмма\n",
        "    chroma_stft = lb.feature.chroma_stft(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "    # Сборка параметров в общий список:\n",
        "    # На один файл один усредненный вектор признаков\n",
        "    features = {'rmse': rmse.mean(axis=1, keepdims=True),\n",
        "                'spct': spec_cent.mean(axis=1, keepdims=True),\n",
        "                'spbw': spec_bw.mean(axis=1, keepdims=True),\n",
        "                'roff': rolloff.mean(axis=1, keepdims=True),\n",
        "                'zcr' : zcr.mean(axis=1, keepdims=True),\n",
        "                'mfcc': mfcc.mean(axis=1, keepdims=True),\n",
        "                'stft': chroma_stft.mean(axis=1, keepdims=True)}\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "1r-KwEK4xtTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция объединения признаков в набор векторов\n",
        "\n",
        "def stack_features(feat  # словарь признаков, отдельные векторы по ключу каждого признака\n",
        "                   ):\n",
        "    features = None\n",
        "    for v in feat.values():\n",
        "        features = np.vstack((features, v)) if features is not None else v\n",
        "\n",
        "    return features.T.reshape(-1).tolist()"
      ],
      "metadata": {
        "id": "l9o--I4Qx0on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# преобразуем полученные признаки в данные для обучения модели\n",
        "X_data = np.array([stack_features(get_features(np.array(i))) for i in data_x]).astype('float32')\n",
        "Y_data = to_categorical(data_y, CC)\n",
        "\n",
        "print(type(X_data), type(Y_data), '\\n', X_data.shape, Y_data.shape)"
      ],
      "metadata": {
        "id": "YpwzwLv4x5x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# импортируем библиотеки для базовой модели\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "2Dl7aIhTx-D6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, sep='\\n')"
      ],
      "metadata": {
        "id": "HnJBOMHIyE2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline([\n",
        "    ('scaling', StandardScaler()),\n",
        "    ('clf', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_Os7WhVlyKVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pipeline(steps=[('scaling', StandardScaler()), ('clf', KNeighborsClassifier())])"
      ],
      "metadata": {
        "id": "Vl34v3TUyO9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# точность предсказания базовой модели\n",
        "y_pred = pipe.predict(X_test)\n",
        "accuracy_score(y_pred, y_test)"
      ],
      "metadata": {
        "id": "xlLcFJuryTyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подход номер три\n",
        "\n",
        "Сгенерируйте данные для обучения модели МОДЕЛЬ ПРЕОБРАЗОВАНИЯ TEXT-TO-SPEECH SILERO используется как предварительно обученная модель из PyTorch.\n",
        "\n",
        "Please follow the link to acquire more information about the model"
      ],
      "metadata": {
        "id": "oWMZ7BCAyf3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# вначале установите библиотеки для загрузки и сохранения предварительно обученной модели\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install -q logmmse\n",
        "\n",
        "# установить библиотеки для увеличения данных\n",
        "!pip install -q audiomentations\n",
        "!pip install -q cylimiter"
      ],
      "metadata": {
        "id": "kSOLXga3yYQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries to generate voice command\n",
        "import torch\n",
        "import numpy as np\n",
        "from logmmse import logmmse\n",
        "from omegaconf import OmegaConf\n",
        "from IPython.display import Audio\n",
        "import librosa as lb\n",
        "from librosa import feature as lbf\n",
        "import gdown\n",
        "\n",
        "# import necessary libraries for augmentation\n",
        "import numpy as np\n",
        "import os\n",
        "from random import choice\n",
        "# import functions for data augmentation and create object for transformation"
      ],
      "metadata": {
        "id": "6Oeu7gXtyrMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from audiomentations import Compose, AddGaussianNoise, AirAbsorption, Limiter, RepeatPart, TanhDistortion, TimeMask, TimeStretch"
      ],
      "metadata": {
        "id": "O-_3OdTRywwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and save the model in the variable 'model'\n",
        "language = 'ru'\n",
        "model_id = 'v4_ru'\n",
        "device = torch.device('cpu')\n",
        "\n",
        "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                     model='silero_tts',\n",
        "                                     language=language,\n",
        "                                     speaker=model_id)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "WZ-J5zsXy2iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to generate voice command\n",
        "def commandGenerator(size, command, model, speaker='random', sample_rate=24000):\n",
        "    \"\"\"\n",
        "    the function takes desired size for generated data, text of a voice command,\n",
        "    saved model to generate data, random speaker to overvoice command and\n",
        "    frequency rate\n",
        "    size: size of the final generated tensor\n",
        "    command: text version of voice command\n",
        "    speaker: voice of speaker\n",
        "    sample_rate: frequency rate\n",
        "    return: generated tensor based on function parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # create initial tensor with zeros and shape equals to 'size' parameter\n",
        "    data = torch.zeros(size)\n",
        "\n",
        "    for i in range(size[0]):\n",
        "        # generate a sample\n",
        "        audio = model.apply_tts(text=command,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "        # enhance synthesis with logmmse\n",
        "        audio = torch.tensor(logmmse(np.array(audio), sample_rate,\n",
        "                                     output_file=None, initial_noise=1,\n",
        "                                     window_size=160, noise_threshold=0.15))\n",
        "        # calculate how many zeros to add in the beginning of the generated sample\n",
        "        zeros_add = (size[1] - audio.size(0)) // 2\n",
        "        # Create tensors of zeros for padding\n",
        "        padding_start, padding_end = torch.zeros(zeros_add), torch.zeros(size[1] - audio.size(0) - zeros_add)\n",
        "        # Concatenate tensors\n",
        "        sample = torch.cat([padding_start, audio, padding_end])\n",
        "        data[i] += sample\n",
        "\n",
        "    return data if data.size(0) == size[0] and data.size(1) == size[1] else \"Error Size\""
      ],
      "metadata": {
        "id": "yo2pDK8Ty7Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentation(source, key, size=2500):\n",
        "    \"\"\"\n",
        "    функция принимает сгенерированные данные из цифровых сетей в виде 2D-тензора\n",
        "     и строка в качестве ключа для применения значений словарей\n",
        "     источник: 2D-тензор\n",
        "     ключ: ключ словаря\n",
        "     вернуть data_x, data_y как список массивов, состоящих из дополненных данных\n",
        "    \"\"\"\n",
        "    data_x, data_y = list(), list()\n",
        "    while len(data_x) != size:\n",
        "\n",
        "        augment = Compose([\n",
        "            AddGaussianNoise(min_amplitude=0.01, max_amplitude=0.04, p=.5),\n",
        "            AirAbsorption(min_distance=300.0, max_distance=700.0, p=.5),\n",
        "            Limiter(min_threshold_db=-40.0, max_threshold_db=-0.0, threshold_mode=\"relative_to_signal_peak\", p=.5),\n",
        "            TanhDistortion(min_distortion=0.01, max_distortion=0.7, p=.5),\n",
        "            TimeMask(min_band_part=0.1, max_band_part=0.2, fade=True, p=.5),\n",
        "            TimeStretch(min_rate=0.7, max_rate=1.5, leave_length_unchanged=True, p=.5),\n",
        "        ])\n",
        "\n",
        "        try:\n",
        "            sample = augment(source[np.random.randint(0, source.size(0))], 24000)\n",
        "        except:\n",
        "            continue\n",
        "        else:\n",
        "            data_x.append(sample), data_y.append(commands_list[key][0])\n",
        "\n",
        "    return data_x, data_y\n",
        "\n"
      ],
      "metadata": {
        "id": "wNsJAeGMzCrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создать вспомогательные данные для создания набора данных train\n",
        "rows = 100\n",
        "commands_size = {'forward': (rows, 60000), 'backward': (rows, 60000), 'stop': (rows, 50000), 'left': (rows, 73000), 'right': (rows, 73000)}\n",
        "commands_list = {'forward': (0, 'иди вперёд'), 'backward': (1, 'иди назад'), 'stop': (2, 'остановись'),\n",
        "                 'left': (3, 'поворачивай влево'), 'right': (4, 'поворачивай вправо')}\n",
        "# create lists to collect data right after an augmentation\n",
        "X_data, Y_data = list(), list()"
      ],
      "metadata": {
        "id": "qJF1kYLRzIxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создайте данные для набора данных train с помощью функции «commandGenerator», используя цикл\n",
        "for key in commands_size:\n",
        "    print(commands_size[key], commands_list[key][1], commands_list[key][0])\n",
        "    source = commandGenerator(commands_size[key], commands_list[key][1], model, speaker='random', sample_rate=24000)\n",
        "    data_x, data_y = augmentation(source, key)\n",
        "    print(len(data_x), len(data_y), data_y[0], data_y[-1])\n",
        "    X_data.extend(data_x), Y_data.extend(data_y)"
      ],
      "metadata": {
        "id": "65zVVIkQzNdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверьте правильность данных и сохраните их\n",
        "print(len(X_data), len(Y_data))\n",
        "\n",
        "torch.save(Y_data, 'tensor_y.pt'), torch.save(X_data, 'tensor_x.pt')"
      ],
      "metadata": {
        "id": "crshrVglzejv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10000\n",
        "display(Audio(X_data[a], rate=24000)), Y_data[a]"
      ],
      "metadata": {
        "id": "c1zvK62Wzf7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определите ссылку загрузчика файла на облачном хранилище Яндекс Диск\n",
        "file_link = 'https://downloader.disk.yandex.ru/disk/c2478dcdbedf0f7c4d9a2f4472918f881e3ccee1082808f4c7b6f6213469f482/65553f37/fKqInKw3d7bLFOeFnMGnhNZsoTigsCIpYapgTpsof6zYW45Nj5YUVxW_mxlG5Ock8SFQlGtGuWGgj4_L4UpnQLSKSGLNlve4hFbmF5cZiRyr8npumZHI4midPdWhecNq?uid=1130000058358976&filename=tensor_x.pt&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=1130000058358976&fsize=1730339726&hid=d766bf1215d7ba8783d3ccbb6c7af7b9&media_type=compressed&tknv=v2&etag=b6b0a0d438adc2e7bd67362f1f334177'\n",
        "# Загрузите файл с помощью gdown\n",
        "output_path = '/content/commands_x'\n",
        "gdown.download(file_link, output_path, quiet=True)\n",
        "\n",
        "# Загрузите тензор PyTorch из загруженного файла\n",
        "data_x = torch.load(output_path)\n",
        "\n",
        "# Проверьте загруженный тензор"
      ],
      "metadata": {
        "id": "HpKOZhWazlPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определите ссылку загрузчика файла на облачном хранилище Яндекс Диск\n",
        "file_link = 'https://downloader.disk.yandex.ru/disk/7ca8dc8dcb1a6ab171c99d76f3e60f801fc1e54b1989caa27e820f13c1491781/6555403b/fKqInKw3d7bLFOeFnMGnhNa4Akt7dfMo_GA1DeFMnTLRCRRoGbMbtdXURS8aTmjm58eZyPCGfAklXGXo-gyqn5Tzk9p7Ju-nKA7_IdpEqfur8npumZHI4midPdWhecNq?uid=1130000058358976&filename=tensor_y.pt&disposition=attachment&hash=&limit=0&content_type=application%2Fzip&owner_uid=1130000058358976&fsize=25892&hid=2f4f6ab50d7ee2b8f33766e2c6786868&media_type=compressed&tknv=v2&etag=b1a729b6a797352739bfad624cf1cfe2'\n",
        "#Загрузите файл с помощью gdown\n",
        "output_path = '/content/commands_y'\n",
        "gdown.download(file_link, output_path, quiet=True)\n",
        "\n",
        "# Загрузите тензор PyTorch из загруженного файла.\n",
        "data_y = torch.load(output_path)\n",
        "\n",
        "# Проверьте загруженный тензор\n",
        "print(len(data_y))"
      ],
      "metadata": {
        "id": "moEHmrcMzrg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2490\n",
        "display(Audio(data_x[a], rate=24000)), data_y[a]"
      ],
      "metadata": {
        "id": "WmP5vjDFzwnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подход номер четыре\n",
        "\n",
        "Features.ipynb"
      ],
      "metadata": {
        "id": "BadfX7jGz51g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings # to suppress warnings\n",
        "import numpy as np # to work with arrays\n",
        "import pandas as pd # to work with dataframes\n",
        "import torch # to work with tensors\n",
        "from IPython.display import Audio # to play audio\n",
        "\n",
        "import librosa as lb # to work with audio files\n",
        "from librosa import feature as lbf # to extract features from audio files\n",
        "\n",
        "import matplotlib.pyplot as plt # to plot graphs\n",
        "import seaborn as sns # to plot graphs\n",
        "sns.set(style='dark', palette='bright') # to set style and palette of graphs\n",
        "\n",
        "from sklearn.model_selection import train_test_split # to split data into train and test sets\n",
        "from sklearn.pipeline import Pipeline # to create a pipeline of transformers\n",
        "from sklearn.compose import ColumnTransformer # to preprocess columns of a dataframe\n",
        "from sklearn.base import BaseEstimator, TransformerMixin # to create custom transformers\n",
        "from sklearn.preprocessing import MinMaxScaler # to scale features\n",
        "from sklearn.model_selection import GridSearchCV # to perform grid search\n",
        "from sklearn.metrics import accuracy_score # to calculate accuracy\n",
        "from sklearn.linear_model import  LogisticRegression # to create a logistic regression model\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader # to create a custom dataset of tensors\n",
        "from torch import nn # to create neural network layers\n",
        "import torchvision.transforms as transforms # to transform data\n",
        "from torch import optim # to create an optimizer\n",
        "from torch import sigmoid, relu, tanh # to create activation functions\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "tZR_DBI8z017"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib-venn"
      ],
      "metadata": {
        "id": "KFehkqCR0A_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "id": "MjZnfEYi0GEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "id": "67SDuRtt0LiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engine.selection import DropDuplicateFeatures # to drop duplicate features"
      ],
      "metadata": {
        "id": "MBqB5jMo0Xja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engine.selection import SmartCorrelatedSelection # to drop correlated features"
      ],
      "metadata": {
        "id": "PHzkCsSU0cxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Извлечение функций из голосовых команд"
      ],
      "metadata": {
        "id": "OhQ_aFQk0oUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузите набор данных в виде списков\n",
        "# 0-2499: forward, 2500-4999: backward, 5000-7499: stop, 7500-9999: left, 10000-12499: right\n",
        "# 0: forward, 1: backward, 2: stop, 3: left, 4: right\n",
        "try:\n",
        "    x = torch.load('tensor_x.pt')\n",
        "    y = torch.load('tensor_y.pt')\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tensor: {e}\")"
      ],
      "metadata": {
        "id": "g1FFG3Lu0iqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверьте набор данных после загрузки\n",
        "idx = 2500\n",
        "display(Audio(x[idx], rate=24000)), y[idx]"
      ],
      "metadata": {
        "id": "j85x6jeq1Pjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to extract features from the audio\n",
        "\n",
        "def get_features(y, sample_rate=24000, n_nfft=1024):\n",
        "    '''\n",
        "    the function extracts features from the audio signal\n",
        "    y: audio signal\n",
        "    sample_rate: sampling rate\n",
        "    n_nfft: number of FFTs\n",
        "    return: dictionary of features\n",
        "    '''\n",
        "    # extract spectral features\n",
        "    # short-time Fourier transform\n",
        "    chroma_stft = lbf.chroma_stft(y=y, sr=sample_rate, n_fft=n_nfft)\n",
        "    # contstant-Q chromagram\n",
        "    chroma_cqt = lbf.chroma_cqt(y=y, sr=sample_rate)\n",
        "    # chroma energy normalized\n",
        "    chroma_cens = lbf.chroma_cens(y=y, sr=sample_rate)\n",
        "    # variable-Q chromagram\n",
        "    chroma_vqt = lbf.chroma_vqt(y=y, sr=sample_rate, intervals='equal')\n",
        "    # mel-scaled spectrogram\n",
        "    melsp = lbf.melspectrogram(y=y, sr=sample_rate, n_fft=n_nfft)\n",
        "    # mel-frequency cepstral coefficients\n",
        "    mffc = lbf.mfcc(y=y, sr=sample_rate, n_fft=n_nfft)\n",
        "    # root-mean-square value for each frame\n",
        "    rmse = lbf.rms(y=y, frame_length=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # spectral centroid\n",
        "    spec_cent = lbf.spectral_centroid(y=y, sr=sample_rate, n_fft=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # p'th-order spectral bandwidth\n",
        "    spec_bw = lbf.spectral_bandwidth(y=y, sr=sample_rate, n_fft=n_nfft, hop_length=n_nfft//2, center=True, p=2)\n",
        "    # spectral contrast\n",
        "    spec_contrast = lbf.spectral_contrast(y=y, sr=sample_rate, n_fft=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # spectral flatness\n",
        "    spec_flatness = lbf.spectral_flatness(y=y, n_fft=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # spectral roll-off frequency\n",
        "    rolloff = lbf.spectral_rolloff(y=y, sr=sample_rate, n_fft=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # nth-order polynomial\n",
        "    poly = lbf.poly_features(y=y, sr=sample_rate, n_fft=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "    # tonal centroid features\n",
        "    tonnetz = lbf.tonnetz(y=y, sr=sample_rate)\n",
        "    # zero-crossing rate\n",
        "    zcr = lbf.zero_crossing_rate(y=y, frame_length=n_nfft, hop_length=n_nfft//2, center=True)\n",
        "\n",
        "    # # extract rhythm features\n",
        "    # # tempo (beats per minute)\n",
        "    # tempo = lbf.tempo(y=y, sr=sample_rate)\n",
        "    # # temprogram\n",
        "    # tempogram = lbf.tempogram(y=y, sr=sample_rate, hop_length=n_nfft//2, win_length=n_nfft, center=True)\n",
        "    # # fourier tempogram\n",
        "    # ftempogram = lbf.fourier_tempogram(y=y, sr=sample_rate, hop_length=n_nfft//2, win_length=n_nfft, center=True)\n",
        "    # # tempogram ratio features\n",
        "    # temp_ratio = lbf.tempogram(y=y, sr=sample_rate, hop_length=n_nfft//2, win_length=n_nfft, center=True)\n",
        "\n",
        "    # collect features in a dictionary\n",
        "    features = {'stft': chroma_stft.mean(axis=1, keepdims=True),\n",
        "                'cqt': chroma_cqt.mean(axis=1, keepdims=True),\n",
        "                'cens': chroma_cens.mean(axis=1, keepdims=True),\n",
        "                'vqt': chroma_vqt.mean(axis=1, keepdims=True),\n",
        "                'melsp': melsp.mean(axis=1, keepdims=True),\n",
        "                'mffc': mffc.mean(axis=1, keepdims=True),\n",
        "                'rmse': rmse.mean(axis=1, keepdims=True),\n",
        "                'spec_cent': spec_cent.mean(axis=1, keepdims=True),\n",
        "                'spec_bw': spec_bw.mean(axis=1, keepdims=True),\n",
        "                'spec_contrast': spec_contrast.mean(axis=1, keepdims=True),\n",
        "                'spec_flatness': spec_flatness.mean(axis=1, keepdims=True),\n",
        "                'rolloff': rolloff.mean(axis=1, keepdims=True),\n",
        "                'poly': poly.mean(axis=1, keepdims=True),\n",
        "                'tonnetz': tonnetz.mean(axis=1, keepdims=True),\n",
        "                'zcr': zcr.mean(axis=1, keepdims=True),\n",
        "                # 'tempo': tempo.reshape(1, -1),\n",
        "                # 'tempogram': tempogram.mean(axis=1, keepdims=True),\n",
        "                # 'ftempogram': ftempogram.mean(axis=1, keepdims=True),\n",
        "                # 'temp_ratio': temp_ratio.mean(axis=1, keepdims=True)\n",
        "                }\n",
        "    return features"
      ],
      "metadata": {
        "id": "ktYxrRFF1UKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary of features and their number\n",
        "features_number = { key: value.shape[0] for key, value in get_features(x[0].numpy()).items() }\n",
        "# create a list of columns names of each feature for the dataframe\n",
        "features_columns = [ key if value == 1 else key + '_' + str(i) for key, value in features_number.items() for i in range(value) ]\n",
        "features_columns[:7], len(features_columns)"
      ],
      "metadata": {
        "id": "t11mECtG1dqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a function to join all features in one vector\n",
        "def stack_features(feat):\n",
        "    '''\n",
        "    the function joins all features in one vector\n",
        "    feat: dictionary of features\n",
        "    return: list of features\n",
        "    '''\n",
        "    features = None\n",
        "    for v in feat.values():\n",
        "        features = np.vstack((features, v)) if features is not None else v\n",
        "\n",
        "    return features.T.reshape(-1).tolist()"
      ],
      "metadata": {
        "id": "6fYBGHu71jG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# преобразуем полученные признаки в данные для обучения модели\n",
        "X_data = np.array([stack_features(get_features(np.array(i))) for i in x]).astype('float32')"
      ],
      "metadata": {
        "id": "YETCiTMo1oH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with features and target\n",
        "df = pd.DataFrame(X_data, columns=features_columns)\n",
        "df['target'] = y # add target column\n",
        "# save the dataframe as a csv file\n",
        "df.to_csv('features.csv', index=False, sep=',')"
      ],
      "metadata": {
        "id": "qrDrEJ8A1s6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('features.csv').drop_duplicates() # load the dataframe and drop duplicates\n",
        "df.reset_index(drop=True, inplace=True) # reset the index\n",
        "df.shape # check the shape of the dataframe"
      ],
      "metadata": {
        "id": "ybEUIvgq1w92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Базовая модель обучения для классификации голосовых команд"
      ],
      "metadata": {
        "id": "Vyfb2Ke011Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5, 2)) # set the size of the graph\n",
        "ax = df.target.value_counts().sort_index().plot(kind='bar', title='Target distribution', rot=0) # plot the graph\n",
        "ax.yaxis.grid(True) # show horizontal grid\n",
        "plt.show() # show the graph"
      ],
      "metadata": {
        "id": "V97SYUdR17ke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}