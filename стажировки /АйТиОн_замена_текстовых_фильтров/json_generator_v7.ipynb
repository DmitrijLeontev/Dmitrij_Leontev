{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitrijLeontev/Dmitrij_Leontev/blob/main/%D1%81%D1%82%D0%B0%D0%B6%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B8%20/%D0%90%D0%B9%D0%A2%D0%B8%D0%9E%D0%BD_%D0%B7%D0%B0%D0%BC%D0%B5%D0%BD%D0%B0_%D1%82%D0%B5%D0%BA%D1%81%D1%82%D0%BE%D0%B2%D1%8B%D1%85_%D1%84%D0%B8%D0%BB%D1%8C%D1%82%D1%80%D0%BE%D0%B2/json_generator_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "id": "NvC021RbHuuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0fdcc1-aced-4734-853e-e4722fb8393f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ru-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.7.0/ru_core_news_sm-3.7.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from ru-core-news-sm==3.7.0) (3.7.4)\n",
            "Collecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3-2.0.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.7.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->ru-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: pymorphy3-dicts-ru, dawg-python, pymorphy3, ru-core-news-sm\n",
            "Successfully installed dawg-python-0.7.2 pymorphy3-2.0.1 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dateparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQiTEWIrOp_r",
        "outputId": "1fdb0ff7-a755-46dc-9faa-4e11cc590e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser) (2023.4)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser) (2023.12.25)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser) (5.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser) (1.16.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import dateparser\n",
        "from datetime import datetime, date\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "qLQ4ACPrO7iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sx-ToB_8gMxs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65371e1b-0552-4e08-f4d2-f417a0a456bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# рабочая папка\n",
        "work_path = '/content/drive/MyDrive/NLP_spacy'\n",
        "\n",
        "# папка для сохранения дообученной модели\n",
        "output_dir = work_path+'/new_NER4'\n",
        "if not os.path.isdir(output_dir): print('Папка', output_dir, 'не найдена!')\n",
        "\n",
        "# загузим ранее сохраненную NER-модель из папки output_dir\n",
        "print(\"Loading from\", output_dir)\n",
        "nlp = spacy.load(output_dir)"
      ],
      "metadata": {
        "id": "BL0M_wY7gfyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_lIWwHYMXjMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка правильности распознавания названий городов\n",
        "\n",
        "import difflib  # Модуль difflib предоставляет функции для вычисления и применения операций различия между последовательностями.\n",
        "\n",
        "def load_city_list(file_path):  # Загружам список городов из текстового файла.\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        cities = [line.strip() for line in f]\n",
        "    return cities\n",
        "\n",
        "def find_closest_city(city, city_list):   # Находим ближайший город в списке с использованием метода наибольшего общего подпоследовательности.\n",
        "    matches = difflib.get_close_matches(city, city_list, n=1, cutoff=0.6)   # n - число возвращаемых совпадений, cutoff -  минимальный порог сходства\n",
        "    # get_close_matches - возвращает список ближайших совпадений, найденных в city_list\n",
        "    # n - число возвращаемых совпадений, cutoff -  минимальный порог сходства\n",
        "    closest_city = matches[0] if len(matches) > 0 else None\n",
        "    return closest_city\n",
        "\n",
        "def correct_city(city, city_list):    # Обработка списока городов и проверка на соответствие.\n",
        "\n",
        "    closest_city = find_closest_city(city, city_list)\n",
        "    if city == \"Питер\" or city == \"Ленинград\":        # Выявленная замена\n",
        "        closest_city = \"Санкт-Петербург\"\n",
        "    if city == \"Минводы\" or city == \"Кавминводы\"  or city == \"Каменвода\" or city == \"Каменводы\":     # Выявленная замена\n",
        "        closest_city = \"Минеральные Воды\"\n",
        "    if city == \"Нижний Арктовского\" or city == \"Нижний Арктовский\":     # Выявленная замена\n",
        "        closest_city = \"Нижневартовск\"\n",
        "\n",
        "    return closest_city\n",
        "\n",
        "\n",
        "# Загрузка списка городов из файла\n",
        "file_path = \"/content/drive/MyDrive/NLP_spacy/city_list.txt\"  # Путь к файлу \".txt\" списка городов\n",
        "\n",
        "all_cities = load_city_list(file_path)\n",
        "# Можно добавить списки других городов, например других стран\n",
        "# railway_cities = load_city_list('railway_cities.txt')\n",
        "# airport_cities = load_city_list('airport_cities.txt')\n",
        "# bus_cities = load_city_list('bus_cities.txt')\n",
        "# all_cities = all_cities + railway_cities + airport_cities + bus_cities\n"
      ],
      "metadata": {
        "id": "k2Gj5qV5XjER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-Rnxp9hsP48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# служебные функции \"добавить\" и \"умножить\"\n",
        "def add(count): return lambda x: x+count\n",
        "def mul(count): return lambda x: x*count if x > 0 else count\n",
        "\n",
        "# словарь вариантов токенов\n",
        "startTokens = {\n",
        "    \"один\": add(1), \"одна\": add(1), \"одного\": add(1),\n",
        "    \"два\": add(2),  \"две\": add(2), \"двое\": add(2), \"вдвоём\": add(2),\n",
        "    \"три\": add(3), \"трое\": add(3), \"втроём\": add(3),\n",
        "    \"четыре\": add(4), \"четверо\": add(4), \"вчетвером\": add(4),\n",
        "    \"пять\": add(5), \"пятеро\": add(5), \"впятером\": add(5),\n",
        "    \"шесть\": add(6), \"шестеро\": add(6), \"вшестером\": add(6),\n",
        "    \"семь\": add(7), \"семеро\": add(7),\n",
        "    \"восемь\": add(8),\n",
        "    \"девять\": add(9),\n",
        "\n",
        "    \"десяток\": mul(10), \"десятка\": mul(10), \"десятков\": mul(10),\n",
        "\n",
        "    \"десять\": add(10),\n",
        "    \"одиннадцать\": add(11),\n",
        "    \"двенадцать\": add(12),\n",
        "    \"тринадцать\": add(13),\n",
        "    \"четырнадцать\": add(14),\n",
        "    \"пятнадцать\": add(15),\n",
        "    \"шестнадцать\": add(16),\n",
        "    \"семнадцать\": add(17),\n",
        "    \"восемнадцать\": add(18),\n",
        "    \"девятнадцать\": add(19),\n",
        "    \"двадцать\": add(20),\n",
        "    \"тридцать\": add(30),\n",
        "    \"сорок\": add(40),\n",
        "    \"пятьдесят\": add(50),\n",
        "    \"шестьдесят\": add(60),\n",
        "    \"семьдесят\": add(70),\n",
        "    \"восемьдесят\": add(80),\n",
        "    \"девяносто\": add(90),\n",
        "\n",
        "    \"сотня\": mul(100), \"сотни\": mul(100), \"сотен\": mul(100),\n",
        "\n",
        "    \"сто\": add(100),\n",
        "    \"двести\": add(200),\n",
        "    \"триста\": add(300),\n",
        "    \"четыреста\": add(400),\n",
        "    \"пятьсот\": add(500),\n",
        "    \"шестьсот\": add(600),\n",
        "    \"семьсот\": add(700),\n",
        "    \"восемьсот\": add(800),\n",
        "    \"девятьсот\": add(900),\n",
        "\n",
        "    \"тысяча\": mul(1000), \"тысячи\": mul(1000), \"тысяч\": mul(1000), \"тыс\": mul(1000)\n",
        "}\n",
        "\n",
        "# функция определения действия по токену\n",
        "def matchToken(token):\n",
        "  try:\n",
        "    return startTokens[token]\n",
        "  except:\n",
        "    if token.isdigit():\n",
        "      return add(int(token))\n",
        "    return add(0)\n",
        "\n",
        "\n",
        "# функция для преобразования числа, заданного словами, в число\n",
        "def str2num(st):\n",
        "\n",
        "    if st.isdigit():\n",
        "      return int(st)\n",
        "\n",
        "    tokens = st.split(\" \")\n",
        "    value = 0\n",
        "    for token in tokens:\n",
        "      value = matchToken(token)(value)\n",
        "\n",
        "    return value\n"
      ],
      "metadata": {
        "id": "_W4xaG0ibfIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция, которая формирует новую пустую поездку\n",
        "def get_new_route():\n",
        "\n",
        "    route = {\n",
        "        'city_from': None,     # город отправления (может быть null)\n",
        "        'date_from': None,     # дата отправления (может быть null)\n",
        "        'date_from_t': None,   # дата отправления, если не удалось определить точное значение (может быть null)\n",
        "        'time_from': None,     # время отправления (может быть null)\n",
        "        'city_to': None,       # город прибытия (может быть null)\n",
        "        'date_to': None,       # дата прибытия (может быть null)\n",
        "        'date_to_t': None,     # дата прибытия, если не удалось определить точное значение (может быть null)\n",
        "        'time_to': None,       # время прибытия (может быть null)\n",
        "        'amount': None,        # количество пассажиров (минимум один)\n",
        "        'transit': None,       # количество пересадок (может быть null)\n",
        "#        'replace_city': None,  # города для возможных пересадок (может быть null)\n",
        "        'transport': None,     # вид транспорта -  'поезд', 'самолет', 'автобус', 'паром' (может быть null)\n",
        "        'company': None,       # компания-перевозчик (может быть null)\n",
        "        'animal': None,        # с животными (может быть null)\n",
        "        'children': None,      # количество детей (может быть null)\n",
        "        'baggage': None,       # с багажом (может быть null)\n",
        "        'level': None,         # класс обслуживания - 'бизнес', 'эконом', 'купе', 'плацкарт' (может быть null)\n",
        "        'comfort': None,       # список дополнительных пожеланий - 'нижняя полка', 'мягкий вагон', 'с питанием', 'женское купе', 'не у туалета', 'биотуалет'  (может быть null)\n",
        "        'insurance': None      # страховка (может быть null)\n",
        "    }\n",
        "\n",
        "    return route\n",
        "\n",
        "\n",
        "# Функция, которая формирует json на основе выделенных сущностей\n",
        "def create_json(doc, filename, transcribator='whisper(model=large)'):\n",
        "\n",
        "    entities = [{'text': ent.text, 'lemma': ent.lemma_, 'label': ent.label_} for ent in doc.ents]\n",
        "\n",
        "    json_data = {\n",
        "        'route': [],                      # маршрут - список поездок (обязательно должен быть хотя бы один элемент)\n",
        "        'all_budget': None,               # общий бюджет на весь маршрут (может быть null)\n",
        "        'filename': filename,             # название транскрибированного аудиофайла\n",
        "#        'real_text': None,\n",
        "        'transcrib_text': doc.text,       # транскрибированный текст\n",
        "        'transcribator': transcribator    # использованный транскрибатор\n",
        "    }\n",
        "\n",
        "    # настройки для парсера дат\n",
        "    settings = {\n",
        "        'DATE_ORDER': 'DMY',\n",
        "        'PREFER_DATES_FROM': 'future'\n",
        "    }\n",
        "\n",
        "    #format_date = '%d.%m.%Y'\n",
        "    format_date = '%d.%m'\n",
        "\n",
        "    route = get_new_route()  # создаем новую поездку\n",
        "    pred_route = route.copy()  # нужно определить и предыдущую поездку\n",
        "\n",
        "    new_route = True\n",
        "    ll = len(entities)\n",
        "    for i in range(ll):\n",
        "        entity = entities[i]\n",
        "        if entity['label'] == 'LOC':  # анализ сущности LOCATION\n",
        "            if i > 0:\n",
        "                entity_pred = entities[i-1]\n",
        "            else:\n",
        "                entity_pred = entity\n",
        "            if (entity_pred['label'] == 'FROM'):  # если предыдущая сущность FROM, то это город отправления\n",
        "                route['city_from'] = correct_city(entity['lemma'].title().replace('.', ''), all_cities)\n",
        "            elif (entity_pred['label'] == 'TO'):  # если предыдущая сущность TO, то это город назначения\n",
        "                route['city_to'] = correct_city(entity['lemma'].title().replace('.', ''), all_cities)\n",
        "            elif entity_pred['label'] == 'TRANSIT':  # если предыдущая сущность TRANSIT, то это город пересадки\n",
        "                if new_route:\n",
        "               #     route['replace_city'] = []\n",
        "                    new_route = False\n",
        "                # if route['replace_city'] is None:\n",
        "                #     route['replace_city'] = []\n",
        "                # route['replace_city'].append(entity['lemma'].title().replace('.', ''))\n",
        "                route['transit'] = 1\n",
        "            elif route['city_from'] is None:  # если предыдущая сущность не подходящая, город отправления определен, а город назначения еще не определен, то это город назначения\n",
        "                route['city_from'] = correct_city(entity['lemma'].title().replace('.', ''), all_cities)\n",
        "            elif route['city_to'] is None:  # если предыдущая сущность не подходящая и город отправления еще не определен, то это город отправления\n",
        "                route['city_to'] = correct_city(entity['lemma'].title().replace('.', ''), all_cities)\n",
        "        elif entity['label'] == 'DATE':  # анализ сущности DATE\n",
        "            if i > 0:\n",
        "                entity_pred = entities[i-1]\n",
        "            else:\n",
        "                entity_pred = entity\n",
        "            if (entity_pred['label'] == 'ARRIVAL'):  # проверим предыдущую сущность, если она ARRIVAL, то это дата прибытия\n",
        "                st = entity['lemma']\n",
        "                if st.find('числ') > -1:  # если найдем \"число\", то заменим на месяц от текущей даты\n",
        "                    st = st.replace('число', datetime.strftime(date.today(), '%B'))\n",
        "                dt = dateparser.parse(st, settings=settings)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_to'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "                route['date_to_t'] = entity['text']\n",
        "            elif route['date_from_t'] is None:  # записываем в дату отправления, если она еще не задана\n",
        "                st = entity['lemma']\n",
        "                if st.find('числ') > -1:  # если найдем \"число\", то заменим на текущий месяц\n",
        "                    if pred_route['date_from'] is not None:  # если была предыдущая поездка и определена дата отправления\n",
        "                        st = st.replace('число', datetime.strptime(pred_route['date_from'], format_date).strftime('%B'))\n",
        "                    elif pred_route['date_to'] is not None:  # ... или определена дата прибытия\n",
        "                        st = st.replace('число', datetime.strptime(pred_route['date_to'], format_date).strftime('%B'))\n",
        "                    else:  # иначе возьмем месяц от текущей даты\n",
        "                        st = st.replace('число', datetime.strftime(date.today(), '%B'))\n",
        "                dt = dateparser.parse(st, settings=settings)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_from'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "                route['date_from_t'] = entity['text']\n",
        "            else:  # а если дата отправления уже определена, то записываем в дату прибытия\n",
        "                st = entity['lemma']\n",
        "                if st.find('числ') > -1:  # если найдем \"число\", то заменим на текущий месяц\n",
        "                    if route['date_from'] is not None:  # если определена дата отправления\n",
        "                        st = st.replace('число', datetime.strptime(route['date_from'], format_date).strftime('%B'))\n",
        "                    else:  # иначе возьмем месяц от текущей даты\n",
        "                        st = st.replace('число', datetime.strftime(date.today(), '%B'))\n",
        "                dt = dateparser.parse(st, settings=settings)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_to'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "                route['date_to_t'] = entity['text']\n",
        "        elif entity['label'] == 'GAP':  # анализ сущности GAP\n",
        "            if i > 0:\n",
        "                entity_pred = entities[i-1]\n",
        "            else:\n",
        "                entity_pred = entity\n",
        "            if i < ll-1:\n",
        "                entity_next = entities[i+1]\n",
        "            else:\n",
        "                entity_next = entity\n",
        "            if (entity_pred['label'] == 'RETURN') or (entity_next['label'] == 'RETURN'):\n",
        "                # проверим предыдущую и следующую сущность и, если она RETURN, то анализ GAP пропускаем - будет выполняться при анализе RETURN\n",
        "                continue\n",
        "            elif route['date_from_t'] is None:  # записываем в дату отправления, если она еще не задана\n",
        "                dt = dateparser.parse(entity['text'], settings=settings)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_from'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "                route['date_from_t'] = entity['text']\n",
        "            else:  # а если дата отправления уже определена, то записываем в дату прибытия\n",
        "                dt = dateparser.parse(entity['text'], settings=settings)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_to'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "                route['date_to_t'] = entity['text']\n",
        "        elif entity['label'] == 'TIME':  # анализ сущности TIME\n",
        "            if route['time_from'] is None:  # проверим время отправления, если оно еще не задано\n",
        "                # дополнительно проверим даты отправления и прибытия\n",
        "                # если дата отправления не задана, а дата прибытия определена, то скорее всего это время прибытия\n",
        "                if (route['date_from_t'] is None) and (route['date_to_t'] is not None):\n",
        "                    route['time_to'] = entity['text']\n",
        "                else:  # в других случаях - время отправления\n",
        "                    route['time_from'] = entity['text']\n",
        "            else:  # а если время отправления уже определено, то записываем во время прибытия\n",
        "                route['time_to'] = entity['text']\n",
        "        elif entity['label'] == 'TRANSIT':  # здесь отлавливаем \"без пересадок\"\n",
        "            if entity['text'].find('без') == -1: route['transit'] = 0\n",
        "        elif entity['label'] == 'AMOUNT':  # кол-во пассажиров\n",
        "            route['amount'] = str2num(entity['lemma'].replace('.', ''))\n",
        "        elif entity['label'] == 'TRANSPORT':  # добавляем вид транспорта\n",
        "            if route['transport'] is None: route['transport'] = []\n",
        "            route['transport'].append(entity['lemma'].replace('.', ''))\n",
        "        elif entity['label'] == 'ORG':  # добавляем вид организацию-перевозчика\n",
        "            if route['company'] is None: route['company'] = []\n",
        "            route['company'].append(entity['lemma'].title().replace('.', ''))\n",
        "        elif entity['label'] == 'ANIMAL':  # \"без животных\" или есть какие-то животные\n",
        "            route['animal'] = entity['text'].find('без') == -1\n",
        "        elif entity['label'] == 'CHILD':  # кол-во детей, с проверкой на \"без детей\"\n",
        "            if entity['text'].find('без') > -1:\n",
        "                route['children'] = 0\n",
        "            else:\n",
        "                col = str2num(entity['lemma'].replace('.', ''))\n",
        "                if col == 0: col = 1\n",
        "                route['children'] = col\n",
        "        elif entity['label'] == 'BAGG':  # \"без багажа\" или есть какой-то багаж\n",
        "            route['baggage'] = entity['text'].find('без') == -1\n",
        "        elif entity['label'] == 'LEVEL':  # добавляем уровень обслуживания\n",
        "            if route['level'] is None: route['level'] = []\n",
        "            route['level'].append(entity['text'])\n",
        "        elif entity['label'] == 'COMFORT':  # добавляем пожелания к комфорту\n",
        "            if route['comfort'] is None: route['comfort'] = []\n",
        "            route['comfort'].append(entity['text'])\n",
        "        elif entity['label'] == 'INSUR':  # \"без страховки\" или страховка есть\n",
        "            route['insurance'] = entity['text'].find('без') == -1\n",
        "        elif entity['label'] == 'BUDGET':  # общий бюджет\n",
        "            json_data['all_budget'] = str2num(entity['lemma'].replace('.', ''))\n",
        "        elif entity['label'] == 'RETURN':\n",
        "            # если встречаем сущность RETURN, то формируем новую поездку, в которую записываем города отправления и прибытия из предыдущей поездки, но в обратном порядке\n",
        "            # все остальные сущности просто копируем, предполагая, что все ранее определенные особенности поездки будут такими же\n",
        "            # при этом даты не копируем, т.к. ясно, что обратная поездка будет позже\n",
        "            # если дальше при разборе фразы будут найдены сущности характеристик поездки, то просто перезапишем\n",
        "            # особенность с транзитными городами: если находим сущность TRANSIT, то обнуляем транзитные города предыдущей поездки\n",
        "\n",
        "            if i > 0:\n",
        "                entity_pred = entities[i-1]\n",
        "            else:\n",
        "                entity_pred = entity\n",
        "            if entity_pred['label'] == 'RETURN': continue  # не обрабатываем, если несколько сущностей RETURN идет подряд\n",
        "\n",
        "            if (route['date_from_t'] is None) and (route['date_to_t'] is None):  # если дата отправления осталась не опеределенной, то заполняем ее текущей датой\n",
        "                route['date_from'] = datetime.strftime(date.today(), format_date)\n",
        "                route['date_from_t'] = ''\n",
        "\n",
        "            pred_route = route.copy()  # скопируем текущую поездку\n",
        "            json_data['route'].append(route)  # добавляем текущую поездку в маршрут\n",
        "            route = get_new_route()  # создаем новую поездку\n",
        "            new_route = True\n",
        "\n",
        "            # заполним некоторые параметры новой поездки на основании предыдущей\n",
        "            route['city_from'] = pred_route['city_to']\n",
        "            route['city_to'] = pred_route['city_from']\n",
        "            route['transit'] = pred_route['transit']\n",
        "            #route['replace_city'] = pred_route['replace_city']\n",
        "            route['amount'] = pred_route['amount']\n",
        "            route['transport'] = pred_route['transport']\n",
        "            route['animal'] = pred_route['animal']\n",
        "            route['children'] = pred_route['children']\n",
        "            route['baggage'] = pred_route['baggage']\n",
        "            route['level'] = pred_route['level']\n",
        "            route['comfort'] = pred_route['comfort']\n",
        "            route['insurance'] = pred_route['insurance']\n",
        "\n",
        "            if i < ll-1:\n",
        "                entity_next = entities[i+1]\n",
        "            else:\n",
        "                entity_next = entity\n",
        "            if (entity_pred['label'] == 'GAP') or (entity_next['label'] == 'GAP'):  # проверим предыдущую и следующую сущность, если она GAP, то попробуем определить дату отправления для новой поездки\n",
        "                if entity_pred['label'] == 'GAP':\n",
        "                    route['date_from_t'] = entity_pred['text']\n",
        "                else:\n",
        "                    route['date_from_t'] = entity_next['text']\n",
        "                settings_modify = settings.copy()\n",
        "                # в настройки парсера дат добавляем \"считать от даты...\"\n",
        "                if pred_route['date_from'] is not None: # если определена дата отправления\n",
        "                    settings_modify['RELATIVE_BASE'] = datetime.strptime(pred_route['date_from'], format_date)\n",
        "                elif pred_route['date_to'] is not None: # если определена дата прибытия\n",
        "                    settings_modify['RELATIVE_BASE'] = datetime.strptime(pred_route['date_to'], format_date)\n",
        "                # или останется текущая дата\n",
        "\n",
        "                dt = dateparser.parse(route['date_from_t'], settings=settings_modify)\n",
        "                if dt is None: dt = date.today()\n",
        "                route['date_from'] = datetime.strftime(dt, format_date)  # если парсер не сможет определить дату, то будет текущая\n",
        "\n",
        "    json_data['route'].append(route)  # добавляем текущую поездку в маршрут\n",
        "\n",
        "    return json_data"
      ],
      "metadata": {
        "id": "D_7PuJZRX4w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xhhJH4mBj_7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# тестирование инициализированной модели\n",
        "#test_text = \"Самолет до Москвы из Владивостока. Там нужно быть 5 мая вечером. Какие есть варианты? На двоих пассажиров без детей. Без багажа. Можно даже через Новосибирск. Обратно 26 числа. Покажи все, что есть. Общий бюджет 10000 рублей.\"\n",
        "#test_text = \"Самолет до Москвы из Владивостока на 5 мая. Какие есть варианты? На двоих пассажиров без детей. Без багажа. Без пересадок. Ну и потом обратно. Где-то 20 мая. Покажи все, что есть. Общий бюджет 10000 рублей.\"\n",
        "#test_text = \"Срочно покажи поезд ближайший на сегодня 20 ноября из Комсомольска на Амуре до Хабаровска, ближайший, который есть. С прибытием не позже 6 утра следующего дня.\"\n",
        "\n",
        "test_text = \"Какие есть варианты добраться 15 декабря из Краснодара в Новосибирск? Обратный возврат 19 декабря пассажир 1.\"\n",
        "\n",
        "doc = nlp(test_text)\n",
        "\n",
        "print([(w.text, w.pos_) for w in doc])\n",
        "print()\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "print()\n",
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "vNUj1iN6H04u",
        "outputId": "9179e152-63e6-4836-df69-3cccada58e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Какие', 'DET'), ('есть', 'VERB'), ('варианты', 'NOUN'), ('добраться', 'VERB'), ('15', 'ADJ'), ('декабря', 'NOUN'), ('из', 'ADP'), ('Краснодара', 'PROPN'), ('в', 'ADP'), ('Новосибирск', 'PROPN'), ('?', 'PUNCT'), ('Обратный', 'ADJ'), ('возврат', 'NOUN'), ('19', 'ADJ'), ('декабря', 'NOUN'), ('пассажир', 'NOUN'), ('1', 'NUM'), ('.', 'PUNCT')]\n",
            "\n",
            "Entities [('15 декабря', 'DATE'), ('из', 'FROM'), ('Краснодара', 'LOC'), ('в', 'TO'), ('Новосибирск', 'LOC'), ('Обратный', 'RETURN'), ('возврат', 'RETURN'), ('19 декабря', 'DATE'), ('пассажир 1.', 'AMOUNT')]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Какие есть варианты добраться \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    15 декабря\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    из\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FROM</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Краснодара\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    в\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TO</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Новосибирск\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "? \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Обратный\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">RETURN</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    возврат\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">RETURN</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    19 декабря\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    пассажир 1.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">AMOUNT</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities = [{'text': ent.text, 'lemma': ent.lemma_, 'label': ent.label_} for ent in doc.ents]\n",
        "entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWrtelJOR3I",
        "outputId": "dfe7f93a-67fd-4e87-e3c7-54a7108cb17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': '15 декабря', 'lemma': '15 декабрь', 'label': 'DATE'},\n",
              " {'text': 'из', 'lemma': 'из', 'label': 'FROM'},\n",
              " {'text': 'Краснодара', 'lemma': 'краснодар', 'label': 'LOC'},\n",
              " {'text': 'в', 'lemma': 'в', 'label': 'TO'},\n",
              " {'text': 'Новосибирск', 'lemma': 'новосибирск', 'label': 'LOC'},\n",
              " {'text': 'Обратный', 'lemma': 'обратный', 'label': 'RETURN'},\n",
              " {'text': 'возврат', 'lemma': 'возврат', 'label': 'RETURN'},\n",
              " {'text': '19 декабря', 'lemma': '19 декабрь', 'label': 'DATE'},\n",
              " {'text': 'пассажир 1.', 'lemma': 'пассажир 1.', 'label': 'AMOUNT'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'audio_01_01.wav'\n",
        "\n",
        "# jsonfile = ''.join(filename.split('.')[:-1])+'.json'\n",
        "# with open(jsonfile, 'w') as fp:\n",
        "#     json.dump(create_json(doc, filename), fp, ensure_ascii=False, indent=4)\n",
        "\n",
        "create_json(doc, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL_m9hkvFxOZ",
        "outputId": "582011f7-625d-4d8d-de86-2c45a542d623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'route': [{'city_from': 'Краснодар',\n",
              "   'date_from': '15.12',\n",
              "   'date_from_t': '15 декабря',\n",
              "   'time_from': None,\n",
              "   'city_to': 'Новосибирск',\n",
              "   'date_to': None,\n",
              "   'date_to_t': None,\n",
              "   'time_to': None,\n",
              "   'amount': None,\n",
              "   'transit': None,\n",
              "   'transport': None,\n",
              "   'company': None,\n",
              "   'animal': None,\n",
              "   'children': None,\n",
              "   'baggage': None,\n",
              "   'level': None,\n",
              "   'comfort': None,\n",
              "   'insurance': None},\n",
              "  {'city_from': 'Новосибирск',\n",
              "   'date_from': '19.12',\n",
              "   'date_from_t': '19 декабря',\n",
              "   'time_from': None,\n",
              "   'city_to': 'Краснодар',\n",
              "   'date_to': None,\n",
              "   'date_to_t': None,\n",
              "   'time_to': None,\n",
              "   'amount': 1,\n",
              "   'transit': None,\n",
              "   'transport': None,\n",
              "   'company': None,\n",
              "   'animal': None,\n",
              "   'children': None,\n",
              "   'baggage': None,\n",
              "   'level': None,\n",
              "   'comfort': None,\n",
              "   'insurance': None}],\n",
              " 'all_budget': None,\n",
              " 'filename': 'audio_01_01.wav',\n",
              " 'transcrib_text': 'Какие есть варианты добраться 15 декабря из Краснодара в Новосибирск? Обратный возврат 19 декабря пассажир 1.',\n",
              " 'transcribator': 'whisper(model=large)'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OavSQkaY9eMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_transcribator = 'whisper(model=large)'\n",
        "input_path = work_path + '/' + name_transcribator\n",
        "output_path = work_path + '/' + name_transcribator + '_json'\n",
        "\n",
        "if not os.path.isdir(input_path):\n",
        "    print('Папка', input_path, 'не найдена!')\n",
        "else:\n",
        "    if not os.path.isdir(output_path): os.makedirs(output_path)\n",
        "\n",
        "    # получим список файлов в папке с данными\n",
        "    file_list = sorted([f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))])\n",
        "    len(file_list)"
      ],
      "metadata": {
        "id": "5Jzm2CaV_Q80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сформируем список тикеров, для которых есть файлы с данными\n",
        "count_files = 0\n",
        "for filename in file_list:\n",
        "    count_files += 1\n",
        "    with open(os.path.join(input_path, filename), 'r', encoding='utf-8') as f:\n",
        "        txt = f.read()\n",
        "    print('#', count_files, ' ', filename, end='   ')\n",
        "    doc = nlp(txt)\n",
        "    js = create_json(doc, filename, transcribator=name_transcribator)\n",
        "    # print('')\n",
        "    # print(js)\n",
        "\n",
        "    jsonfile = ''.join(filename.split('.')[:-1])+'.json'\n",
        "    with open(os.path.join(output_path, jsonfile), 'w') as fp:\n",
        "        json.dump(js, fp, ensure_ascii=False, indent=4)\n",
        "    print('+')\n",
        "    # print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SU0Dr3n-zM8",
        "outputId": "39b58ff0-8897-404d-e529-487838ab4c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 1   audio_2023-11-20_18-04-29.txt   +\n",
            "# 2   audio_2023-11-20_18-04-59.txt   +\n",
            "# 3   audio_2023-11-20_18-05-06.txt   +\n",
            "# 4   audio_2023-11-20_18-05-12.txt   +\n",
            "# 5   audio_2023-11-20_18-05-18.txt   +\n",
            "# 6   audio_2023-11-20_18-06-06.txt   +\n",
            "# 7   audio_2023-11-20_18-06-10.txt   +\n",
            "# 8   audio_2023-11-20_18-06-14.txt   +\n",
            "# 9   audio_2023-11-20_18-06-20.txt   +\n",
            "# 10   audio_2023-11-20_18-06-26.txt   +\n",
            "# 11   audio_2023-11-20_18-06-31.txt   +\n",
            "# 12   audio_2023-11-20_18-06-41.txt   +\n",
            "# 13   audio_2023-11-20_18-06-58.txt   +\n",
            "# 14   audio_2023-11-20_18-07-03.txt   +\n",
            "# 15   audio_2023-11-20_18-07-09.txt   +\n",
            "# 16   audio_2023-11-20_18-07-15.txt   +\n",
            "# 17   audio_2023-11-20_18-07-19.txt   +\n",
            "# 18   audio_2023-11-20_18-07-23.txt   +\n",
            "# 19   audio_2023-11-20_18-07-27.txt   +\n",
            "# 20   audio_2023-11-20_18-08-03.txt   +\n",
            "# 21   audio_2023-11-20_18-08-06.txt   +\n",
            "# 22   audio_2023-11-20_18-08-17.txt   +\n",
            "# 23   audio_2023-11-20_18-08-21.txt   +\n",
            "# 24   audio_2023-11-20_18-08-24.txt   +\n",
            "# 25   audio_2023-11-20_18-08-28.txt   +\n",
            "# 26   audio_2023-11-20_18-10-59.txt   +\n",
            "# 27   audio_2023-11-20_18-11-03.txt   +\n",
            "# 28   audio_2023-11-20_18-11-48.txt   +\n",
            "# 29   audio_2023-11-20_18-12-00.txt   +\n",
            "# 30   audio_2023-11-20_18-12-04.txt   +\n",
            "# 31   audio_2023-11-20_18-12-09.txt   +\n",
            "# 32   audio_2023-11-20_18-12-27.txt   +\n",
            "# 33   audio_2023-11-20_18-12-31.txt   +\n",
            "# 34   audio_2023-11-20_18-12-35.txt   +\n",
            "# 35   audio_2023-11-20_18-12-38.txt   +\n",
            "# 36   audio_2023-11-20_18-12-44.txt   +\n",
            "# 37   audio_2023-11-20_18-12-50.txt   +\n",
            "# 38   audio_2023-11-20_18-12-59.txt   +\n",
            "# 39   audio_2023-11-20_18-13-03.txt   +\n",
            "# 40   audio_2023-11-20_18-13-15.txt   +\n",
            "# 41   audio_2023-11-20_18-13-30.txt   +\n",
            "# 42   audio_2023-11-20_18-13-34.txt   +\n",
            "# 43   audio_2023-11-20_18-13-37.txt   +\n",
            "# 44   audio_2023-11-20_18-13-41.txt   +\n",
            "# 45   audio_2023-11-20_18-13-45.txt   +\n",
            "# 46   audio_2023-11-20_18-14-06.txt   +\n",
            "# 47   audio_2023-11-20_18-14-09.txt   +\n",
            "# 48   audio_2023-11-20_18-14-12.txt   +\n",
            "# 49   audio_2023-11-20_18-14-15.txt   +\n",
            "# 50   audio_2023-11-20_18-14-18.txt   +\n",
            "# 51   audio_2023-11-20_18-14-29.txt   +\n",
            "# 52   audio_2023-11-20_18-14-33.txt   +\n",
            "# 53   audio_2023-11-20_18-14-37.txt   +\n",
            "# 54   audio_2023-11-20_18-14-40.txt   +\n",
            "# 55   audio_2023-11-20_18-14-44.txt   +\n",
            "# 56   audio_2023-11-20_18-14-50.txt   +\n",
            "# 57   audio_2023-11-20_18-15-12.txt   +\n",
            "# 58   audio_2023-11-20_18-15-15.txt   +\n",
            "# 59   audio_2023-11-20_18-15-19.txt   +\n",
            "# 60   audio_2023-11-20_18-15-21.txt   +\n",
            "# 61   audio_2023-11-20_18-15-25.txt   +\n",
            "# 62   audio_2023-11-20_18-15-32.txt   +\n",
            "# 63   audio_2023-11-20_18-15-38.txt   +\n",
            "# 64   audio_2023-11-20_18-15-45.txt   +\n",
            "# 65   audio_2023-11-20_18-15-48.txt   +\n",
            "# 66   audio_2023-11-20_18-15-57.txt   +\n",
            "# 67   audio_2023-11-20_18-16-01.txt   +\n",
            "# 68   audio_2023-11-20_18-16-04.txt   +\n",
            "# 69   audio_2023-11-20_18-16-07.txt   +\n",
            "# 70   audio_2023-11-20_18-16-11.txt   +\n",
            "# 71   audio_2023-11-20_18-16-16.txt   +\n",
            "# 72   audio_2023-11-20_18-16-21.txt   +\n",
            "# 73   audio_2023-11-20_18-16-24.txt   +\n",
            "# 74   audio_2023-11-20_18-16-28.txt   +\n",
            "# 75   audio_2023-11-20_18-16-39.txt   +\n",
            "# 76   audio_2023-11-20_18-29-52.txt   +\n",
            "# 77   audio_2023-11-20_18-29-55.txt   +\n",
            "# 78   audio_2023-11-20_18-29-58.txt   +\n",
            "# 79   audio_2023-11-20_18-36-22.txt   +\n",
            "# 80   audio_2023-11-20_18-36-26.txt   +\n",
            "# 81   audio_2023-11-20_18-36-29.txt   +\n",
            "# 82   audio_2023-11-20_18-36-34.txt   +\n",
            "# 83   audio_2023-11-20_18-36-38.txt   +\n",
            "# 84   audio_2023-11-20_18-36-44.txt   +\n",
            "# 85   audio_2023-11-20_18-36-47.txt   +\n",
            "# 86   audio_2023-11-20_18-36-51.txt   +\n",
            "# 87   audio_2023-11-20_18-36-58.txt   +\n",
            "# 88   audio_2023-11-20_18-37-01.txt   +\n",
            "# 89   audio_2023-11-20_18-39-09.txt   +\n",
            "# 90   audio_2023-11-20_18-39-14.txt   +\n",
            "# 91   audio_2023-11-20_19-49-33.txt   +\n",
            "# 92   audio_2023-11-20_19-49-38.txt   +\n",
            "# 93   audio_2023-11-20_19-49-41.txt   +\n",
            "# 94   audio_2023-11-20_19-49-45.txt   +\n",
            "# 95   audio_2023-11-20_19-49-48.txt   +\n",
            "# 96   audio_2023-11-20_19-49-52.txt   +\n",
            "# 97   audio_2023-11-20_19-49-57.txt   +\n",
            "# 98   audio_2023-11-20_19-50-01.txt   +\n",
            "# 99   audio_2023-11-20_19-50-05.txt   +\n",
            "# 100   audio_2023-11-20_19-50-11.txt   +\n",
            "# 101   audio_2023-11-21_18-23-35.txt   +\n",
            "# 102   audio_2023-11-21_18-23-39.txt   +\n",
            "# 103   audio_2023-11-21_18-23-43.txt   +\n",
            "# 104   audio_2023-11-21_18-23-46.txt   +\n",
            "# 105   audio_2023-11-21_18-23-50.txt   +\n",
            "# 106   audio_2023-11-21_18-23-54.txt   +\n",
            "# 107   audio_2023-11-21_18-23-57.txt   +\n",
            "# 108   audio_2023-11-21_18-24-01.txt   +\n",
            "# 109   audio_2023-11-21_18-24-09.txt   +\n",
            "# 110   audio_2023-11-21_18-24-12.txt   +\n",
            "# 111   audio_2023-11-21_18-24-15.txt   +\n",
            "# 112   audio_2023-11-21_18-24-18.txt   +\n",
            "# 113   audio_2023-11-21_18-24-22.txt   +\n",
            "# 114   audio_2023-11-21_18-24-25.txt   +\n",
            "# 115   audio_2023-11-21_18-24-35.txt   +\n",
            "# 116   audio_2023-11-21_18-24-38.txt   +\n",
            "# 117   audio_2023-11-21_18-24-42.txt   +\n",
            "# 118   audio_2023-11-21_18-24-45.txt   +\n",
            "# 119   audio_2023-11-21_18-24-49.txt   +\n",
            "# 120   audio_2023-11-21_18-24-56.txt   +\n",
            "# 121   audio_2023-11-21_18-24-59.txt   +\n",
            "# 122   audio_2023-11-21_18-25-02.txt   +\n",
            "# 123   audio_2023-11-21_18-25-05.txt   +\n",
            "# 124   audio_2023-11-21_18-25-08.txt   +\n",
            "# 125   audio_2023-11-21_18-25-13.txt   +\n",
            "# 126   audio_2023-11-23_18-24-46.txt   +\n",
            "# 127   audio_2023-11-23_18-24-50.txt   +\n",
            "# 128   audio_2023-11-23_18-24-55.txt   +\n",
            "# 129   audio_2023-11-23_18-24-58.txt   +\n",
            "# 130   audio_2023-11-23_18-25-02.txt   +\n",
            "# 131   audio_2023-11-23_18-25-06.txt   +\n",
            "# 132   audio_2023-11-23_18-25-10.txt   +\n",
            "# 133   audio_2023-11-23_18-25-14.txt   +\n",
            "# 134   audio_2023-11-23_18-25-20.txt   +\n",
            "# 135   audio_2023-11-23_18-25-23.txt   +\n",
            "# 136   audio_2023-11-23_18-25-32.txt   +\n",
            "# 137   audio_2023-11-23_18-25-36.txt   +\n",
            "# 138   audio_2023-11-23_18-25-40.txt   +\n",
            "# 139   audio_2023-11-23_18-25-44.txt   +\n",
            "# 140   audio_2023-11-23_19-58-09.txt   +\n",
            "# 141   audio_2023-11-23_19-58-13.txt   +\n",
            "# 142   audio_2023-11-23_19-58-16.txt   +\n",
            "# 143   audio_2023-11-23_19-58-29.txt   +\n",
            "# 144   audio_2023-11-23_19-58-32.txt   +\n",
            "# 145   audio_2023-11-23_19-58-35.txt   +\n",
            "# 146   audio_2023-11-23_19-58-39.txt   +\n",
            "# 147   audio_2023-11-23_19-58-42.txt   +\n",
            "# 148   audio_2023-11-23_19-58-47.txt   +\n",
            "# 149   audio_2023-11-23_19-58-52.txt   +\n",
            "# 150   audio_2023-11-23_19-58-57.txt   +\n",
            "# 151   audio_2023-12-01_09-08-52.txt   +\n",
            "# 152   audio_2023-12-01_09-08-55.txt   +\n",
            "# 153   audio_2023-12-01_09-09-01.txt   +\n",
            "# 154   audio_2023-12-01_09-09-04.txt   +\n",
            "# 155   audio_2023-12-01_09-09-07.txt   +\n",
            "# 156   audio_2023-12-01_09-09-10.txt   +\n",
            "# 157   audio_2023-12-01_09-09-15.txt   +\n",
            "# 158   audio_2023-12-01_09-09-17.txt   +\n",
            "# 159   audio_2023-12-01_09-09-26.txt   +\n",
            "# 160   audio_2023-12-01_09-09-30.txt   +\n",
            "# 161   audio_2023-12-01_09-09-36.txt   +\n",
            "# 162   audio_2023-12-01_09-09-40.txt   +\n",
            "# 163   audio_2023-12-01_09-09-43.txt   +\n",
            "# 164   audio_2023-12-01_09-09-46.txt   +\n",
            "# 165   audio_2023-12-01_09-09-50.txt   +\n",
            "# 166   audio_2023-12-01_09-09-55.txt   +\n",
            "# 167   audio_2023-12-01_09-10-00.txt   +\n",
            "# 168   audio_2023-12-01_09-10-04.txt   +\n",
            "# 169   audio_2023-12-01_09-10-08.txt   +\n",
            "# 170   audio_2023-12-01_09-10-53.txt   +\n",
            "# 171   audio_2023-12-01_09-10-57.txt   +\n",
            "# 172   audio_2023-12-01_09-11-01.txt   +\n",
            "# 173   audio_2023-12-01_09-11-06.txt   +\n",
            "# 174   audio_2023-12-01_09-11-09.txt   +\n",
            "# 175   audio_2023-12-01_09-11-15.txt   +\n",
            "# 176   audio_2023-12-01_09-11-19.txt   +\n",
            "# 177   audio_2023-12-01_09-11-23.txt   +\n",
            "# 178   audio_2023-12-01_09-11-29.txt   +\n",
            "# 179   audio_2023-12-01_09-11-33.txt   +\n",
            "# 180   audio_2023-12-01_09-11-37.txt   +\n",
            "# 181   audio_2023-12-01_09-11-41.txt   +\n",
            "# 182   audio_2023-12-01_09-11-48.txt   +\n",
            "# 183   audio_2023-12-01_09-11-52.txt   +\n",
            "# 184   audio_2023-12-01_09-11-55.txt   +\n",
            "# 185   audio_2023-12-01_09-12-03.txt   +\n",
            "# 186   audio_2023-12-01_09-12-08.txt   +\n",
            "# 187   audio_2023-12-01_09-12-13.txt   +\n",
            "# 188   audio_2023-12-01_09-12-17.txt   +\n",
            "# 189   audio_2023-12-01_09-12-23.txt   +\n",
            "# 190   audio_2023-12-01_09-12-28.txt   +\n",
            "# 191   audio_2023-12-01_09-12-31.txt   +\n",
            "# 192   audio_2023-12-01_09-12-35.txt   +\n",
            "# 193   audio_2023-12-01_09-12-41.txt   +\n",
            "# 194   audio_2023-12-01_09-12-45.txt   +\n",
            "# 195   audio_2023-12-01_09-12-50.txt   +\n",
            "# 196   audio_2023-12-01_09-12-54.txt   +\n",
            "# 197   audio_2023-12-01_09-12-59.txt   +\n",
            "# 198   audio_2023-12-01_09-13-03.txt   +\n",
            "# 199   audio_2023-12-01_09-13-06.txt   +\n",
            "# 200   audio_2023-12-01_09-13-09.txt   +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mueg9wK9eBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}